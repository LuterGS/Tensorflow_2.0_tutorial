import tensorflow as tf

if __name__=="__main__":

    """
여기엔 중요 실행 코드가 없다. 왜냐? 여기는 코드설명이 아니고 개념설명 파일이니까.
이걸 왜 파이썬 파일로 만들었냐고? 내맘이야 ㅋㅋ



특징 추출

    특징 추출... 컨벌루션 신경망은 보통 이미지같은, 특징들로만 이루어져 있지 않은 데이터가 입력이다. 즉, 입력을 먼저 신경망에서 정제해줄 필요가 있다.
    이게 기존 신경망과 뭐가 다르냐고?
    예를 들어보자.
        회귀/분류모델의 입력값은 값 자체가 특징을 띠고있는 값이다. 서울시 관측자료를 예로 들어보면, 관측자료에 들어가는 값 하나하나가 특징값이다.
        습도, 방향(풍속), 지면온도 등등... 입력되는 데이터 자체가 특징값이기 때문에 특징을 정제해줄 필요가 없다.
    CNN에 사용되는 이미지들은 다르다. 흔히 쓰는 개와 고양이 분류 사진같은 경우, 개와 고양이 픽셀 부분만 있는게 아니고, 다른 부분, 전혀 쓸모없거나 상관없는 부분이 표현되어있는 픽셀도 존재한다.
    그런 것들을 모두 신경망에 넣는다면, 그것 때문에 이상한 편향이 일어날 수 있다. 또한, 신경망이 특징을 잘 파악하지 못할 수도 있다. 어떤 것에 중점을 둬야 할지 모를 수 있기 떄문에.
    
    물론, 완전히 RAW Data들을 넣고 그걸 돌렸을때 제대로 특징을 추출한다면 그건 CNN 필터들이 필요없는 완벽한 신경망이겠지만, 인간도 학습할 때 어느정도 가이드라인이 필요한 판에 인공지능한테 
    가이드라인 없이 스스로 자기학습하는걸 원한다? 그건 CNN으로는 안된다. 더 나은 알고리즘을 사용한 것이 필요하다. (강화학습이라던가... 강솨학습이라던가...)
    따라서, 이미지 처리를 위해서는 일단 특징 추출이 필요하다.

    특징 추출의 대표적인 방법은 컨벌루션 연산을 수행하는 것이다. 정확히는, n*n 크기의 픽셀 집합을 하나의 픽셀 집합으로 바꾸는 방법이다. 어떻게 하냐고?
    n*n 크기의 행렬을 하나 준비하고, 그 행렬과 픽셀 집합을 [곱연산후 연산한 행렬값들을 전부 더해주면]시키면 된다. 간단~ 
        곱연산한다는게 중요하다. 행렬곱이 아니고... 행렬곱하면 당연히 똑같운 n*n 행렬이 생기니까... 곱연한수 더해줘야 1*1로 변하지 않겠니?
    해당 행렬을 필터 또는 커널이라고 한다. 필터가 더 입에 붙는 네이밍인거같긴 하다. 특징없는 사진에서 특징을 가려내주니까.
    
    보통 행렬들은 수직선 검출/수평선 검출/블러효과 등등의 사람들이 발견한 필터들이 있지만, 이건 "사람들이 손으로 설계"했다는 특징을 갖는다. 
    뭔 말이냐고? 이 행렬 만드는것도 갓-공지능 님꼐서 해주셔야 진정한 신경망 아니겠니? 그걸 해주는게 CNN이란다.
    
    

주요 레이어 정리

    레이어는 뭐 여러 종류가 있지만. 컨벌루션 신경망은 다음과 같은 구조를 갖는다.
    데이터 - 컨벌루션 필터 적용 - 풀링 - Flatten Layer - Dense Layer - 출력
        혹시나 해서 써놓는다. Flatten Layer는 다차원을 1차원으로 바꿔주는거다. 그냥 여러 차원으로 나눠져있던 행렬들을 한줄로 쭉 이어붙였다 생각해
        Dense는 말그대로 완전연결 신경망, 각 뉴런이 완전연결되어있는 레이어다. 이건 솔직히 기본이니까 알겠지
    
    여기서, 데이터 - 컨벌루션 필터 - 풀링 까지의 과정이 특징추출과정이라, 해당 부분을 특징 추출기 (Feature Extractor) 라고 부른다.
    Dense - (Dropout) - 출력 까지의 과정이 분류라, 해당 부분을 분류기 (Classifier) 라고 한다. 
    정리하면, 특징추출 부분에서 특징추출 해주고, 분류쪽에서 특징추출한 데이터를 바탕으로 분류를 한다. 
        Dropout은 뭐냐고? 과적합을 막기 위해 일부 가중치를 학습시키지 않는 레이어다. 과적합을 막는게 정말 중요하기 떄문에 이걸 쓴다. 
        안써도 상관없다고? 그러다가 과적합되서 트레이닝 셋만 정답률 99% 이상 찍고 새로운거 들어오면 50% 이하로 떨어져보면 정신 차리지 않을까?
        


컨벌루션 레이어

    컨벌루션 연산하는 레이어. 아까전에 말했듯이 필터를 갓-공지능 님꼐서 찾아주시는게 주 목적이다.
    코드에서 지정해야 하는 건, 필터의 개수다. 필터를 체우는 픽셀 값, 그니까 행렬 내부의 값을 지정할 필요가 없다. 인공지능이 해주니까.
    필터의 수가 많으면 많을수록 다양한 특징을 추출할 수 있다.
    필터를 n개 쓰면, 이미지가 n개 만들어진다. 당연하다.
        이걸 배열로 연결해준다고 생각하면, 나머지로 이미지 만들고 이거 배열화시키면 n*[이미지 2차원 배열] 이런 식으로 만들어지겠지?
    잠만 이거 만드는 코드좀 보고오자. """

    convolutional_layer = tf.keras.layers.Conv2D(kernel_size=(3, 3), strides=(2, 2), padding='valid', filters=16)
    """ 그럼 이제 만들었으니 코드를 살펴보자.
     - kernel_size : 커널 사이즈다. 3*3 행렬로 만든다고 선언했네.
     - strides : 연산 후 필터가 이동하는 크기다. 가로/세로 차이인거같은데, 2, 2는 한번 연산후 가로로는 2칸씩 이동하고, 줄바꿈시 세로로 2칸 이동한다.
                 만약 3*4로 잡으면 가로로 3칸씩 이동하고 줄바꿀때 4칸씩 이동하겠지? 그럼 그림 크기도 당연히 달라진다. 총 연산수가 달라지니 당연함.
     - padding : 'valid'나 'same' 2개중 하나를 쓴다. 'valid' 하면, 컨벌루션 연산 적용시에 행렬 계산할때 처음부터 이미지 내부에서 시작한다.
                 예를 들어, 100x100사진, 필터 3x3일때 처음 시작시에 필터 (1,1)부분이 사진 (1,1) 부분과 일치하도록 시작한다.
                 'same' 사용시, 필터의 중앙 부분이 사진의 (1,1) 부분에 오도록 한다. 왜냐고? 연산을 거친 후 나온 결과물의 해상도가 원본과 동일하게 하기 위해서이다.
                 그러려면, 원본 해상도의 바깥쪽에 일종의 dummy 값을 넣어줘서 해상도를 확장시켜야겠지? 만약 이 dummy값이 0이면 zero padding이라고 한단다.
     - filters : 말 그대로 필터의 개수이다. 일종의 신경망에서 node 역할을 하는 것이다. 많으면 특징 추출이 세세해지겠지만 과적합이 발생할 수도 있고, 연산도 오래 걸리겠지?
                 이것도 적절한 타협을 주는 것이 중요하다.
    

풀링 레이어

    이미지 특성상, 인접한 픽셀은 비슷한 값을 가진다. 특히나 자연스러운 사진일수록 더더욱.
    안 그런 사진들도 있다고? 인위적으로 조작하지 않은 이상, 어떤 사진이든 픽셀 단위로 들어가면 인접 픽셀은 비슷한 값을 만든다. 그림판으로 픽셀단위 일일히 찍어내지 않는 이상 말이야,
    여기서, 이 특징들을 유지하고 크기를 줄이면서 중요한 정보만을 남기기 위해, 서브샘플링(subsampling)이란 기법을 사용한다.
    왜 이걸 하냐고? 컴퓨터의 성능이 슈퍼컴퓨터라서 그냥 RAW 이미지 때려넣어도 해주는게 있으면 좋겠지만, 그 컴퓨터도 일반적은 RAW 이상의 해상도 사진들 넣어주면 허덕일걸?
    자원 절약함과 동시에, 불필요한 세세한 특징을 잡아내 과적합을 일으키는 요소도 미연에 방지할 수 있기에 쓴다. 
    이 서브샘플링을 해주는게 풀링 레이어다.
    
    이것도 종류가 많다. Max, Average... 이름만 보고 감을 맞추자면, 아마 MAX는 단위크기 내에서 가장 큰 값, Average는 단위크기 내에서의 평균값을 1x1 픽셀로 치환하는 레이어같다.
    컨벌루션 레이어에는 Max가 많이 쓰인다 하니, 한번 코드를 보자."""

    pooling_layer = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))
    """ 만들어봤으니 코드를 살펴보자.
     - pool_size : Max 연산을 수행할 크기다. 쉽게 말해, conv_layer에서 필터의 크기와 비슷하다. 자, 2, 2로 한다면 2x2사이즈 단위 픽셀집합에서 최댓값만 추출해준다.
     - strides : conv_layer에서 써줬던 것들과 같다. 이거 조정을 어떻게 하느냐에 따라 데이터의 크기가 줄어든다. 지금같은 경우는 2배 줄어든다. 왜 그러냐 하면... 그림을 그려보면 이해가 갈 것이다.
     
    정리하면, 플링 레이어는 서브샘플링을 위해 미리 지정된 필터를 데이터에 적용하는 것이다. 따라서, 가중치같은게 없다. 왜냐? 상수취급이니까. 필터안의 값이 불변이니까...
    따라서 네트워크 구조에 따라 생략될 수도 있다고 한다.
    
    
    
드롭아웃 레이어

    과적합을 막기 위해, 학습시 일부 가중치들을 학습하지 않는 것이다. 어떻게? 일부 뉴런들을 비활성화시키면 된다. 그럼 당연히 가중치는 학습되지 않겠지?
    역전파, 순전파할때의 과정을 생각하면 이해가 갈 것이다. 역전파, 순전파를 모른다고? 저런...
    
    이거도 코드가 있따. 코드를 보자."""

    dropout_layer = tf.keras.layers.Dropout(rate=0.3)
    """ 이것도 만들어봤으니 코드를 살펴보자.
     - rate : 이거 하나밖에 없다. 제외할 뉴런의 비율을 나타낸다. 1로 설정하면 학습이 안된다 ㅋㅋ
              이거도 상수 취급이기 떄문에, 가중치고 뭐고 없다. 그냥 일종의 option같은거라 생각하면 될 듯 하다.
              
              
              
자 설명은 여기까지.
    """